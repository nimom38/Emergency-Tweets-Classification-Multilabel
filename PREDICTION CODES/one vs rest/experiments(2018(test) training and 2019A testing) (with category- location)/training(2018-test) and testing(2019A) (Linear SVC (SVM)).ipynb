{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training(2018-test) and testing(2019A) (Linear SVC (SVM)).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMvQBKWFAkG+wmXUjN6T2fk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":242},"id":"6M4WY2bLJVsO","executionInfo":{"status":"ok","timestamp":1625896518250,"user_tz":-360,"elapsed":45270,"user":{"displayName":"Gazi Mohaimin Iqbal","photoUrl":"","userId":"08231369660200653102"}},"outputId":"9d4c7f93-1216-44fa-ce7b-1f79e6c02c7f"},"source":["import json\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-6a35e97f-9249-4893-b9ee-c20819186af8\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6a35e97f-9249-4893-b9ee-c20819186af8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving __trecis2019-A-test.earthquakeBohol2013.csv to __trecis2019-A-test.earthquakeBohol2013.csv\n","Saving __trecis2019-A-test.earthquakeCalifornia2014.csv to __trecis2019-A-test.earthquakeCalifornia2014.csv\n","Saving __trecis2019-A-test.fireYMM2016.csv to __trecis2019-A-test.fireYMM2016.csv\n","Saving __trecis2019-A-test.floodChoco2019.csv to __trecis2019-A-test.floodChoco2019.csv\n","Saving __trecis2019-A-test.hurricaneFlorence2018.csv to __trecis2019-A-test.hurricaneFlorence2018.csv\n","Saving __trecis2019-A-test.shootingDallas2017.csv to __trecis2019-A-test.shootingDallas2017.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"id":"hvnp3XHaJqUG","executionInfo":{"status":"ok","timestamp":1625896573543,"user_tz":-360,"elapsed":55316,"user":{"displayName":"Gazi Mohaimin Iqbal","photoUrl":"","userId":"08231369660200653102"}},"outputId":"3349c673-7ab6-4ecb-8591-9715d63185e9"},"source":["import json\n","from google.colab import files\n","uploaded = files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-af22d749-8ebd-44d5-8ff6-87c7ca22f7fb\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-af22d749-8ebd-44d5-8ff6-87c7ca22f7fb\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving 2. TestSet_2018.csv to 2. TestSet_2018.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8UitljJSta_","executionInfo":{"status":"ok","timestamp":1625914991602,"user_tz":-360,"elapsed":47571,"user":{"displayName":"Gazi Mohaimin Iqbal","photoUrl":"","userId":"08231369660200653102"}},"outputId":"b94dcead-e948-4d02-94c3-a9336135ac66"},"source":["#### NLTK install\n","!pip install --user -U nltk\n","\n","### Krovetzstemmer install\n","!pip install krovetzstemmer\n","\n","### spacy install\n","!pip install -U spacy\n","!python -m spacy download en_core_web_sm\n","\n","### URL Normalization install\n","!pip install urlextract\n","!pip install idna\n","!pip install uritools\n","!pip install appdirs\n","!pip install dnspython\n","\n","### install language detection\n","!pip install langdetect\n","\n","### install ekphrasis\n","!pip install ekphrasis"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: nltk in /root/.local/lib/python3.7/site-packages (3.6.2)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.41.1)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n","Requirement already satisfied: krovetzstemmer in /usr/local/lib/python3.7/dist-packages (0.8)\n","Requirement already up-to-date: spacy in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.0.0)\n","Requirement already satisfied, skipping upgrade: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.1)\n","Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n","Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n","Requirement already satisfied, skipping upgrade: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.0)\n","Requirement already satisfied, skipping upgrade: thinc<8.1.0,>=8.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.7)\n","Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied, skipping upgrade: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.3.2)\n","Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n","Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n","Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n","Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied, skipping upgrade: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n","Requirement already satisfied, skipping upgrade: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.4)\n","Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n","Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied, skipping upgrade: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.1.0)\n","Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy) (3.4.1)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","2021-07-10 11:02:41.394237: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Requirement already satisfied: en-core-web-sm==3.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl#egg=en_core_web_sm==3.1.0 in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.1.0) (3.1.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.5)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.41.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (57.0.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.23.0)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.7)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n","Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.4.1)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.1.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n","\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","Requirement already satisfied: urlextract in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from urlextract) (2.10)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from urlextract) (1.4.4)\n","Requirement already satisfied: uritools in /usr/local/lib/python3.7/dist-packages (from urlextract) (3.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from urlextract) (3.0.12)\n","Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (2.10)\n","Requirement already satisfied: uritools in /usr/local/lib/python3.7/dist-packages (3.0.2)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (1.4.4)\n","Requirement already satisfied: dnspython in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n","Requirement already satisfied: ekphrasis in /usr/local/lib/python3.7/dist-packages (0.5.1)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (6.0.3)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (0.4.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.19.5)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.2)\n","Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.0.2)\n","Requirement already satisfied: nltk in /root/.local/lib/python3.7/site-packages (from ekphrasis) (3.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.41.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis) (0.2.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (0.10.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (1.0.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (2019.12.20)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->ekphrasis) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySc6jOf8lmWc","executionInfo":{"status":"ok","timestamp":1625915001251,"user_tz":-360,"elapsed":5159,"user":{"displayName":"Gazi Mohaimin Iqbal","photoUrl":"","userId":"08231369660200653102"}},"outputId":"9cfea965-720b-45ce-9012-62fc4d184b9d"},"source":["from nltk.tokenize import TweetTokenizer\n","from nltk.stem.porter import *\n","from nltk.stem.snowball import SnowballStemmer\n","from krovetzstemmer import Stemmer\n","from nltk.corpus import stopwords\n","import nltk\n","nltk.download('stopwords')\n","from gensim.parsing.preprocessing import STOPWORDS\n","import spacy\n","from urlextract import URLExtract\n","from langdetect import detect\n","from ekphrasis.classes.preprocessor import TextPreProcessor\n","from ekphrasis.classes.tokenizer import SocialTokenizer\n","from ekphrasis.dicts.emoticons import emoticons"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"f0tMcwPBPkHX"},"source":["######### TOKENIZATION ##########\n","\n","## NLTK\n","tknzr = TweetTokenizer()\n","def NLTK_TOKENIZE_TWEET(text):\n","  # from nltk.tokenize import TweetTokenizer\n","  temp = tknzr.tokenize(text)\n","  s = \" \"   \n","  return (s.join(temp))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lYjIQZRASXMA"},"source":["######### STEMMING ##########\n","\n","## PORTER STEMMER\n","# from nltk.stem.porter import *\n","stemmer_p = PorterStemmer()\n","def PORTER_STEMMER(text):\n","  li = list(text.split(\" \"))\n","  singles = [stemmer_p.stem(xx) for xx in li]\n","  return (' '.join(singles))\n","\n","## SNOWBALL STEMMER\n","stemmer_s = SnowballStemmer(language='english', ignore_stopwords=True) #ignore_stopwords=False to disable ignoring stopwords\n","def SNOWBALL_STEMMER(text):\n","  li = list(text.split(\" \"))\n","  # from nltk.stem.snowball import SnowballStemmer\n","  singles = [stemmer_s.stem(xx) for xx in li]\n","  return (' '.join(singles))\n","\n","## KROVETZ STEMMER\n","stemmer_k = Stemmer()\n","def KROVETZ_STEMMER(text):\n","  li = list(text.split(\" \"))\n","  # from krovetzstemmer import Stemmer\n","  singles = [stemmer_k.stem(xx) for xx in li]\n","  return (' '.join(singles))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3MU0fRsRZJSY"},"source":["######### STOPWORDS REMOVAL ##########\n","\n","## NLTK\n","all_stopwords_n = stopwords.words('english')\n","def NLTK_STOPWORD(text):\n","  # from nltk.corpus import stopwords\n","  # import nltk\n","  # nltk.download('stopwords')\n","\n","  ###### add new stopwords\n","  # sw_list = ['likes','play']\n","  # all_stopwords_n.extend(sw_list)\n","  ######\n","\n","  ###### remove stopwords\n","  # all_stopwords_n.remove('not')\n","  ######\n","\n","  text_tokens = list(text.split(\" \"))\n","  tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_n]\n","  return (' '.join(tokens_without_sw))\n","\n","## Genism\n","all_stopwords_gensim = STOPWORDS\n","def GENISM_STOPWORD(text):\n","  # from gensim.parsing.preprocessing import STOPWORDS\n","  \n","  ##### add new stopwords\n","  # all_stopwords_gensim = STOPWORDS.union(set(['likes', 'play']))\n","  #####\n","\n","  ##### remove stopwords\n","  # sw_list = {\"not\"}\n","  # all_stopwords_gensim = STOPWORDS.difference(sw_list)\n","  #####\n","\n","  text_tokens = list(text.split(\" \"))\n","  tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]\n","  return (' '.join(tokens_without_sw))\n","\n","## SpacY\n","sp = spacy.load('en_core_web_sm')\n","all_stopwords_s = sp.Defaults.stop_words\n","def SPACY_STOPWORD(text):\n","  # import spacy\n","  \n","  ##### add stopwords\n","  # all_stopwords_s |= {\"likes\",\"tennis\",}\n","  #####\n","\n","  ##### remove stopwords\n","  # all_stopwords_s.remove('not')\n","  #####\n","\n","  text_tokens = list(text.split(\" \"))\n","  tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_s]\n","  return (' '.join(tokens_without_sw))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-f5KQaTaf_24"},"source":["##### SPECIAL CHARACTERS REMOVAL #####\n","\n","## Also removes # and @ (mind you)\n","def special_characters_removal(text):\n","  hmm = \"\"\n","  for ch in text:\n","    if ch.isalnum():\n","      hmm += ch\n","    elif ch == ' ':\n","      hmm += ch\n","  return hmm\n","\n","# print( special_characters_removal('dnjaskd% asjdhibas&j asjdbijb**###@??>< dbiasbdasib.!') )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3X_jvAmnSkP"},"source":["##### URL NORMALIZATION #####\n","extractor = URLExtract()\n","def url_normalization(text):\n","  text_tokens = list(text.split(\" \"))\n","  # from urlextract import URLExtract\n","  for i in range(len(text_tokens)):\n","    example_text = text_tokens[i]\n","    if extractor.has_urls(example_text):\n","      text_tokens[i] = \"url\"\n","  return (' '.join(text_tokens))\n","\n","# print( url_normalization('hihihihi facebook.com yahoo.com http://bit.ly/PdHur https://tinyurl.com/uxtct20') )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-4P7PDQboaIT"},"source":["##### Language Detection #####\n","\n","def lang_detection(text):\n","  # from langdetect import detect\n","  return detect(text)\n","\n","# this function is expected to return \"en\" for english\n","# print(lang_detection('this is english. i speak english. i speak bangla'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKrCIkk9o-RJ"},"source":["##### ekphrasis pipeline #####\n","\n","def ekphrasis_pipeline(text):\n","  # from ekphrasis.classes.preprocessor import TextPreProcessor\n","  # from ekphrasis.classes.tokenizer import SocialTokenizer\n","  # from ekphrasis.dicts.emoticons import emoticons\n","\n","  text_processor = TextPreProcessor(\n","    # terms that will be normalized\n","    # normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n","        # 'time', 'url', 'date', 'number'],\n","    # terms that will be annotated\n","    # annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n","        # 'emphasis', 'censored'},\n","    fix_html=True,  # fix HTML tokens\n","    \n","    # corpus from which the word statistics are going to be used \n","    # for word segmentation \n","    segmenter=\"twitter\", \n","    \n","    # corpus from which the word statistics are going to be used \n","    # for spell correction\n","    corrector=\"twitter\", \n","    \n","    unpack_hashtags=True,  # perform word segmentation on hashtags\n","    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n","    spell_correct_elong=False,  # spell correction for elongated words\n","    \n","    # select a tokenizer. You can use SocialTokenizer, or pass your own\n","    # the tokenizer, should take as input a string and return a list of tokens\n","    # tokenizer=SocialTokenizer(lowercase=True).tokenize,\n","    \n","    # list of dictionaries, for replacing tokens extracted from the text,\n","    # with other expressions. You can pass more than one dictionaries.\n","    # dicts=[emoticons]\n","  )\n","  return (\" \".join(text_processor.pre_process_doc(text)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ou551_gdJs7i"},"source":["diction = {}\n","\n","diction[\"GoodsServices\"] = \"Request-GoodsServices\"\n","diction[\"SearchAndRescue\"] = \"Request-SearchAndRescue\"\n","diction[\"InformationWanted\"] = \"Request-InformationWanted\"\n","diction[\"Volunteer\"] = \"CallToAction-Volunteer\"\n","diction[\"Donations\"] = \"CallToAction-Donations\"\n","diction[\"MovePeople\"] = \"CallToAction-MovePeople\"\n","diction[\"FirstPartyObservation\"] = \"Report-FirstPartyObservation\"\n","diction[\"ThirdPartyObservation\"] = \"Report-ThirdPartyObservation\"\n","diction[\"Weather\"] = \"Report-Weather\"\n","diction[\"EmergingThreats\"] = \"Report-EmergingThreats\"\n","diction[\"NewSubEvent\"] = \"Report-NewSubEvent\"\n","diction[\"MultimediaShare\"] = \"Report-MultimediaShare\"\n","diction[\"ServiceAvailable\"] = \"Report-ServiceAvailable\"\n","diction[\"Factoid\"] = \"Report-Factoid\"\n","diction[\"Official\"] = \"Report-Official\"\n","diction[\"News\"] = \"Report-News\"\n","diction[\"CleanUp\"] = \"Report-CleanUp\"\n","diction[\"Hashtags\"] = \"Report-Hashtags\"\n","diction[\"OriginalEvent\"] = \"Report-OriginalEvent\"\n","diction[\"ContextualInformation\"] = \"Other-ContextualInformation\"\n","diction[\"Advice\"] = \"Other-Advice\"\n","diction[\"Sentiment\"] = \"Other-Sentiment\"\n","diction[\"Discussion\"] = \"Other-Discussion\"\n","diction[\"Irrelevant\"] = \"Other-Irrelevant\"\n","diction[\"Location\"] = \"Report-Location\"\n","ans = []\n","sentences = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XWYvziJknXyg","executionInfo":{"status":"ok","timestamp":1625915043316,"user_tz":-360,"elapsed":11769,"user":{"displayName":"Gazi Mohaimin Iqbal","photoUrl":"","userId":"08231369660200653102"}},"outputId":"15e0ebf5-6b7d-48f7-a2a7-a311753bc6ac"},"source":["text_processor = TextPreProcessor(\n","    # terms that will be normalized\n","    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n","        'time', 'url', 'date', 'number'],\n","    # terms that will be annotated\n","    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n","        'emphasis', 'censored'},\n","    fix_html=True,  # fix HTML tokens\n","    \n","    # corpus from which the word statistics are going to be used \n","    # for word segmentation \n","    segmenter=\"twitter\", \n","    \n","    # corpus from which the word statistics are going to be used \n","    # for spell correction\n","    corrector=\"twitter\", \n","    \n","    unpack_hashtags=True,  # perform word segmentation on hashtags\n","    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n","    spell_correct_elong=False,  # spell correction for elongated words\n","    \n","    # select a tokenizer. You can use SocialTokenizer, or pass your own\n","    # the tokenizer, should take as input a string and return a list of tokens\n","    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n","    \n","    # list of dictionaries, for replacing tokens extracted from the text,\n","    # with other expressions. You can pass more than one dictionaries.\n","    dicts=[emoticons]\n","  )\n","def mass_ekphrasis():\n","  # print(\"len: \", len(sentences))\n","  ans.clear()\n","  # from ekphrasis.classes.preprocessor import TextPreProcessor\n","  # from ekphrasis.classes.tokenizer import SocialTokenizer\n","  # from ekphrasis.dicts.emoticons import emoticons\n","\n","  for s in sentences:\n","    # ans.append(\" \".join(text_processor.pre_process_doc(s)))\n","    ans.append(s)\n","    # print(\" \".join(text_processor.pre_process_doc(s)), -1121321, s)\n","  \n","  #return ans\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n","  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"],"name":"stderr"},{"output_type":"stream","text":["Reading twitter - 1grams ...\n","Reading twitter - 2grams ...\n","Reading twitter - 1grams ...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42\n","  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BZRP7hhHimZh"},"source":["def preprocess_pipeline( text ):\n","  # text = ekphrasis_pipeline(text)\n","  # text = NLTK_TOKENIZE_TWEET(text)\n","  text = PORTER_STEMMER(text)\n","  text = NLTK_STOPWORD(text)\n","  # text = url_normalization(text)\n","  text = special_characters_removal(text)\n","  return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-xYMr0yh4PO"},"source":["def preprocess_preprocess(TT, hmm):\n","  arr = [ TT[0], TT[1] ]\n","  # print(hmm)\n","  temp = preprocess_pipeline( hmm )\n","  arr.append( temp )\n","  for i in range(3, len(TT)):\n","    arr.append( TT[i] )\n","  # print(TT[2], temp)\n","  return tuple(arr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"HVs9UO2yJwX1","executionInfo":{"status":"ok","timestamp":1625915399595,"user_tz":-360,"elapsed":340874,"user":{"displayName":"Gazi Mohaimin Iqbal","photoUrl":"","userId":"08231369660200653102"}},"outputId":"f7ac0a77-4df9-4c71-f995-cc3bdbaf37d0"},"source":["# Import Section\n","import csv\n","import codecs\n","import sys\n","import io\n","import numpy as np\n","import pandas as pd\n","import scipy as sp\n","\n","# For Classifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import LinearSVC\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neural_network import BernoulliRBM\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from statistics import mean\n","\n","# Python script for confusion matrix creation. \n","from sklearn.metrics import *\n","from numpy import mean\n","from numpy import std\n","from sklearn import metrics\n","\n","\n","\n","TrainDataDir=\"2. TestSet_2018.csv\"\n","TestDataDir = [\n","           '__trecis2019-A-test.earthquakeBohol2013.csv',\n","           '__trecis2019-A-test.earthquakeCalifornia2014.csv',\n","           '__trecis2019-A-test.fireYMM2016.csv',\n","           '__trecis2019-A-test.floodChoco2019.csv',\n","           '__trecis2019-A-test.hurricaneFlorence2018.csv',\n","           '__trecis2019-A-test.shootingDallas2017.csv'\n","]\n","\n","numnum = [\n","          'TRECIS-CTIT-H-Test-025',\n","          'TRECIS-CTIT-H-Test-024',\n","          'TRECIS-CTIT-H-Test-028',\n","          'TRECIS-CTIT-H-Test-022',\n","          'TRECIS-CTIT-H-Test-026',\n","          'TRECIS-CTIT-H-Test-027'\n","]\n","\n","frames = []\n","\n","for i in range(6):\n","  files = pd.read_csv(TestDataDir[i])\n","  frames.append(files)\n","  #print(files.columns)\n","\n","result = pd.concat(frames, ignore_index=True)\n","result.set_index('identifier', inplace=True, drop=True)\n","\n","cc = 0\n","for row in result.itertuples(name=None):\n","  cc += 1\n","  #print(row)\n","\n","w, h = 1, cc;\n","Matrix = [[0 for x in range(w)] for y in range(h)]\n","lol = []\n","\n","def main():\n","  DataLoad = pd.read_csv(TrainDataDir)\n","  \n","  #df_label = DataLoad.drop(['AnimeName', 'SearchContents'], axis=1)\n","  #counts = []\n","  #categories = list(df_label.columns.values)\n","  #for i in categories:\n","    #counts.append((i, df_label[i].sum()))\n","  #df_stats = pd.DataFrame(counts, columns=['category', 'number_of_comments'])\n","  #print(df_stats)\n","  categories = [ \"GoodsServices\",\n","          \"SearchAndRescue\",\n","          \"InformationWanted\",\n","          \"Volunteer\",\n","          \"Donations\",\n","          \"MovePeople\",\n","          \"FirstPartyObservation\",\n","          \"ThirdPartyObservation\",\n","          \"Weather\",\n","          \"EmergingThreats\",\n","          \"NewSubEvent\",\n","          \"MultimediaShare\",\n","          \"ServiceAvailable\",\n","          \"Factoid\",\n","          \"Official\",\n","          \"News\",\n","          \"CleanUp\",\n","          \"Hashtags\",\n","          \"OriginalEvent\",\n","          \"ContextualInformation\",\n","          \"Advice\",\n","          \"Sentiment\",\n","          \"Discussion\",\n","          \"Irrelevant\",\n","          \"Location\"]\n","\n","  assert len(categories) == 25\n","\n","  from sklearn.utils import shuffle\n","  # train = shuffle(DataLoad)\n","\n","  ##########################################################################\n","  # print(DataLoad.columns)\n","  arrr = []\n","  sentences.clear()\n","  lol_cnt = 0\n","  damnit = []\n","  for row in DataLoad.itertuples(name=None):\n","    if lang_detection(row[2]) == 'en':\n","      sentences.append(row[2])\n","      damnit.append(1)\n","    else:\n","      damnit.append(0)\n","  # print(-11111111, len(sentences))\n","  mass_ekphrasis()\n","  # print(-22222222, len(sentences), type(sentences))\n","  iii = -1\n","  for row in DataLoad.itertuples(name=None):\n","    # print(row)\n","    iii += 1\n","    if damnit[iii] == 1:\n","      # print(-1321312, ans[lol_cnt], -123123123, row[2])\n","      arrr.append( preprocess_preprocess(row, ans[lol_cnt]) )\n","      lol_cnt += 1\n","  assert lol_cnt == len(ans)\n","  assert lol_cnt == len(sentences)\n","  yoyoyo = ['0'];\n","  for hmm in DataLoad.columns:\n","    yoyoyo.append(hmm)\n","  train = pd.DataFrame(arrr, columns = yoyoyo)\n","  # train.set_index('identifier', drop = True, inplace = True)\n","  train = train.drop(['0'], axis = 1)\n","  # print(train.columns)\n","  # print(train.index)\n","  # print(DataLoad.index)\n","  # print(train.shape)\n","  # print(DataLoad.shape)\n","  # print(\"---------------------------------------------------------\")\n","  #########################################################################\n","\n","  X_train = train.tweet_text\n","\n","  # print(type(X_train))\n","\n","  #print(X_train.shape)\n","  #print(X_test.shape)\n","\n","  ## Define Classifier\n","  from sklearn.svm import LinearSVC\n","  from sklearn.svm import SVC\n","\n","  classifier = Pipeline([\n","     ('count_vectorizer', CountVectorizer(ngram_range=(1, 3))),\n","     ('tfidf', TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)),\n","     ('clf', OneVsRestClassifier(LinearSVC(C=10.0, class_weight=None, dual=True, fit_intercept=True,\n","      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n","      multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n","      verbose=0)))]) \n","\n","\n","  df_predicted=pd.DataFrame()\n","  df_groundTruth=pd.DataFrame()\n","  ok = False\n","  for category in categories:\n","    print('... Processing Category: {}'.format(category))\n","    # train the model using X_dtm & y\n","    # print(X_train)\n","    # print(train[category])\n","    classifier.fit(X_train, train[category])\n","    cnt = 0\n","    for i in range(6):\n","      huhu = pd.read_csv(TestDataDir[i])\n","\n","      #########################################################################\n","      arrr = []\n","      sentences.clear()\n","      lol_cnt = 0\n","      for row in huhu.itertuples(name=None):\n","        sentences.append(row[2])\n","      mass_ekphrasis()\n","      for row in huhu.itertuples(name=None):\n","        # print(row)\n","        arrr.append( preprocess_preprocess(row, ans[lol_cnt]) )\n","        lol_cnt += 1\n","      assert lol_cnt == len(ans)\n","      assert lol_cnt == len(sentences)\n","      yoyoyo = ['0'];\n","      for hmm in huhu.columns:\n","        yoyoyo.append(hmm)\n","      test = pd.DataFrame(arrr, columns = yoyoyo)\n","      # train.set_index('identifier', drop = True, inplace = True)\n","      test = test.drop(['0'], axis = 1)\n","\n","      # print(huhu.columns)\n","      # print(test.columns)\n","      # print(huhu.shape)\n","      # print(test.shape)\n","      # print(huhu.index)\n","      # print(test.index)\n","\n","      ###############################################################################\n","      X_test = test.tweet_text\n","      # print(X_test)\n","      #compute the testing accuracy\n","      prediction = classifier.predict(X_test)\n","      for j in range(len(prediction)):\n","        if prediction[j] == 1:\n","          Matrix[cnt].append('\"' + diction[category] + '\"')\n","        cnt += 1\n","        if ok == False:\n","          lol.append( (numnum[i], j+1) )\n","    ok = True\n","      #print(prediction)\n","      #print(test[category])\n","      #df_predicted[category]=prediction\n","      #df_groundTruth[category]=test[category]\n","      #print('F1 Micro: {}'.format(f1_score(test[category], prediction, average='micro')))\n","\n","  cnt = 0\n","  arr = []\n","  for row in result.itertuples(name=None):\n","    temp = []\n","    temp.append(lol[cnt][0])\n","    temp.append(\"Q0\")\n","    temp.append(row[0])\n","    temp.append(lol[cnt][1])\n","    temp.append(1)\n","    Matrix[cnt].pop(0)\n","    temp.append(Matrix[cnt])\n","    temp.append(\"myrun\")\n","    cnt += 1\n","    arr.append(temp)\n","  \n","  with open(\"file_linearSVC.txt\", 'w') as output:\n","    for row in arr:\n","        output.write(str(row) + '\\n')\n","  from google.colab import files\n","  files.download('file_linearSVC.txt')\n","\n","  print(result.shape)\n","\n","  #y_true = np.array(df_groundTruth)\n","  #y_pred = np.array(df_predicted)\n","\n","  #print(\"\\n\")\n","  #print(\"F1_Micro:\", f1_score(y_true, y_pred, average='micro'))\n","  #print(\"F1_Macro:\", f1_score(y_true, y_pred, average='macro'))\n","  #print(\"Multi-label Accuracy (or Jaccard Index):\", jaccard_score(y_true,y_pred, average='samples'))\n","  #print(\"Hamming_loss:\", hamming_loss(y_true, y_pred))    \n","  \n","  \n","if __name__ == '__main__':\n","  main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["... Processing Category: GoodsServices\n","... Processing Category: SearchAndRescue\n","... Processing Category: InformationWanted\n","... Processing Category: Volunteer\n","... Processing Category: Donations\n","... Processing Category: MovePeople\n","... Processing Category: FirstPartyObservation\n","... Processing Category: ThirdPartyObservation\n","... Processing Category: Weather\n","... Processing Category: EmergingThreats\n","... Processing Category: NewSubEvent\n","... Processing Category: MultimediaShare\n","... Processing Category: ServiceAvailable\n","... Processing Category: Factoid\n","... Processing Category: Official\n","... Processing Category: News\n","... Processing Category: CleanUp\n","... Processing Category: Hashtags\n","... Processing Category: OriginalEvent\n","... Processing Category: ContextualInformation\n","... Processing Category: Advice\n","... Processing Category: Sentiment\n","... Processing Category: Discussion\n","... Processing Category: Irrelevant\n","... Processing Category: Location\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 0 is present in all training examples.\n","  str(classes[c]))\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_8f2168b3-bc5a-49c4-a567-a8b2b11b9387\", \"file_linearSVC.txt\", 600317)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["(5543, 35)\n"],"name":"stdout"}]}]}